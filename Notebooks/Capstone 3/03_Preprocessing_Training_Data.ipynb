{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9423f647",
   "metadata": {},
   "source": [
    "# 3 Preprocessing and Training Data <a id=\"preprocessing_training\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5129c470",
   "metadata": {},
   "source": [
    "## 3.1 Contents <a id=\"contents\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a24ff1b",
   "metadata": {},
   "source": [
    "- [3 Preprocessing and Training Data](#preprocessing_training)\n",
    "  - [3.1 Contents](#contents)\n",
    "  - [3.2 Introduction](#introduction)\n",
    "      - [3.2.1 Objective](#objective)\n",
    "  - [3.3 Imports](#imports)\n",
    "  - [3.4 Load the Data](#dataload)\n",
    "  - [3.5 Define Preprocessor and Pipeline](#preprocessor&pipeline)\n",
    "  - [3.6 Train/Test Split](#train_test_split)\n",
    "  - [3.7 Apply Pipeline: Scaling, Encoding, and Model Training](#scaling&encoding)\n",
    "  - [3.8 Model Evaluation](#modeleval)\n",
    "  - [3.9 Save Data](#savedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e5b7b",
   "metadata": {},
   "source": [
    "## 3.2 Introduction <a id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a38325",
   "metadata": {},
   "source": [
    "We've completed our data wrangling and exploration phases, but now we need to process and gather our training data. Our goal is to find the optimal model that will most accurately classify fraudulent transactions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f99c7e0",
   "metadata": {},
   "source": [
    "### 3.2.1 Objective <a id=\"objective\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4063f",
   "metadata": {},
   "source": [
    "We want to ensure our data is preprocessed so we may implement machine learning algorithms to best predict fraud. We'll start by defining our preprocessor and pipeline, then split into training and testing subsets, scale our data, and encode categorical variables into numerical representation. We'll then end by considering a baseline model and how useful this is as a predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e7a8b",
   "metadata": {},
   "source": [
    "## 3.3 Imports <a id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bbab3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.ticker as tick\n",
    "import sklearn.model_selection\n",
    "\n",
    "from sklearn import neighbors, datasets, preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a164ba7a",
   "metadata": {},
   "source": [
    "## 3.4 Load the Data <a id=\"dataload\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e949bd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>sending_address</th>\n",
       "      <th>receiving_address</th>\n",
       "      <th>amount</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>location_region</th>\n",
       "      <th>ip_prefix</th>\n",
       "      <th>login_frequency</th>\n",
       "      <th>session_duration</th>\n",
       "      <th>...</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>fraud</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>amount_per_login</th>\n",
       "      <th>duration_per_login</th>\n",
       "      <th>same_address_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-11 12:47:27</td>\n",
       "      <td>12</td>\n",
       "      <td>0x9d32d0bf2c00f41ce7ca01b66e174cc4dcb0c1da</td>\n",
       "      <td>0x39f82e1c09bc6d7baccc1e79e5621ff812f50572</td>\n",
       "      <td>796.949206</td>\n",
       "      <td>transfer</td>\n",
       "      <td>Europe</td>\n",
       "      <td>192.000</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>18.75</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>265.649735</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-14 19:12:46</td>\n",
       "      <td>19</td>\n",
       "      <td>0xd6e251c23cbf52dbd472f079147873e655d8096f</td>\n",
       "      <td>0x51e8fbe24f124e0e30a614e14401b9bbfed5384c</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>purchase</td>\n",
       "      <td>South America</td>\n",
       "      <td>172.000</td>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>25.00</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>evening</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-18 16:26:59</td>\n",
       "      <td>16</td>\n",
       "      <td>0x2e0925b922fed01f6a85d213ae2718f54b8ca305</td>\n",
       "      <td>0x52c7911879f783d590af45bda0c0ef2b8536706f</td>\n",
       "      <td>778.197390</td>\n",
       "      <td>purchase</td>\n",
       "      <td>Asia</td>\n",
       "      <td>192.168</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>31.25</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>259.399130</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-15 09:20:04</td>\n",
       "      <td>9</td>\n",
       "      <td>0x93efefc25fcaf31d7695f28018d7a11ece55457f</td>\n",
       "      <td>0x8ac3b7bd531b3a833032f07d4e47c7af6ea7bace</td>\n",
       "      <td>300.838358</td>\n",
       "      <td>transfer</td>\n",
       "      <td>South America</td>\n",
       "      <td>172.000</td>\n",
       "      <td>8</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>36.75</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>morning</td>\n",
       "      <td>37.604795</td>\n",
       "      <td>13.875000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-18 14:35:30</td>\n",
       "      <td>14</td>\n",
       "      <td>0xad3b8de45d63f5cce28aef9a82cf30c397c6ceb9</td>\n",
       "      <td>0x6fdc047c2391615b3facd79b4588c7e9106e49f2</td>\n",
       "      <td>775.569344</td>\n",
       "      <td>sale</td>\n",
       "      <td>Africa</td>\n",
       "      <td>172.160</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>62.50</td>\n",
       "      <td>moderate_risk</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>129.261557</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  hour_of_day  \\\n",
       "0  2022-04-11 12:47:27           12   \n",
       "1  2022-06-14 19:12:46           19   \n",
       "2  2022-01-18 16:26:59           16   \n",
       "3  2022-06-15 09:20:04            9   \n",
       "4  2022-02-18 14:35:30           14   \n",
       "\n",
       "                              sending_address  \\\n",
       "0  0x9d32d0bf2c00f41ce7ca01b66e174cc4dcb0c1da   \n",
       "1  0xd6e251c23cbf52dbd472f079147873e655d8096f   \n",
       "2  0x2e0925b922fed01f6a85d213ae2718f54b8ca305   \n",
       "3  0x93efefc25fcaf31d7695f28018d7a11ece55457f   \n",
       "4  0xad3b8de45d63f5cce28aef9a82cf30c397c6ceb9   \n",
       "\n",
       "                            receiving_address      amount transaction_type  \\\n",
       "0  0x39f82e1c09bc6d7baccc1e79e5621ff812f50572  796.949206         transfer   \n",
       "1  0x51e8fbe24f124e0e30a614e14401b9bbfed5384c    0.010000         purchase   \n",
       "2  0x52c7911879f783d590af45bda0c0ef2b8536706f  778.197390         purchase   \n",
       "3  0x8ac3b7bd531b3a833032f07d4e47c7af6ea7bace  300.838358         transfer   \n",
       "4  0x6fdc047c2391615b3facd79b4588c7e9106e49f2  775.569344             sale   \n",
       "\n",
       "  location_region  ip_prefix  login_frequency  session_duration  ...  \\\n",
       "0          Europe    192.000                3                48  ...   \n",
       "1   South America    172.000                5                61  ...   \n",
       "2            Asia    192.168                3                74  ...   \n",
       "3   South America    172.000                8               111  ...   \n",
       "4          Africa    172.160                6               100  ...   \n",
       "\n",
       "  risk_score        anomaly  day_of_week month  fraud  is_weekend  \\\n",
       "0      18.75       low_risk            0     4  False           0   \n",
       "1      25.00       low_risk            1     6  False           0   \n",
       "2      31.25       low_risk            1     1  False           0   \n",
       "3      36.75       low_risk            2     6  False           0   \n",
       "4      62.50  moderate_risk            4     2  False           0   \n",
       "\n",
       "   time_of_day  amount_per_login duration_per_login  same_address_flag  \n",
       "0    afternoon        265.649735          16.000000                  0  \n",
       "1      evening          0.002000          12.200000                  0  \n",
       "2    afternoon        259.399130          24.666667                  0  \n",
       "3      morning         37.604795          13.875000                  0  \n",
       "4    afternoon        129.261557          16.666667                  0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/joshuabe/Downloads/Capstone 3 - Metaverse Fraud Prediction/metaverse_transactions_dataset_cleaned_explored.csv')\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d0c97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78600, 22)\n",
      "        hour_of_day        amount     ip_prefix  login_frequency  \\\n",
      "count  78600.000000  78600.000000  78600.000000     78600.000000   \n",
      "mean      11.532634    502.574903    147.644430         4.178702   \n",
      "std        6.935897    245.898146     69.388143         2.366038   \n",
      "min        0.000000      0.010000     10.000000         1.000000   \n",
      "25%        6.000000    331.319966    172.000000         2.000000   \n",
      "50%       12.000000    500.029500    172.160000         4.000000   \n",
      "75%       18.000000    669.528311    192.000000         6.000000   \n",
      "max       23.000000   1557.150905    192.168000         8.000000   \n",
      "\n",
      "       session_duration    risk_score   day_of_week         month  \\\n",
      "count      78600.000000  78600.000000  78600.000000  78600.000000   \n",
      "mean          69.684606     44.956722      3.003372      6.530153   \n",
      "std           40.524476     21.775365      1.998823      3.453638   \n",
      "min           20.000000     15.000000      0.000000      1.000000   \n",
      "25%           35.000000     26.250000      1.000000      4.000000   \n",
      "50%           60.000000     40.000000      3.000000      7.000000   \n",
      "75%          100.000000     52.500000      5.000000     10.000000   \n",
      "max          159.000000    100.000000      6.000000     12.000000   \n",
      "\n",
      "         is_weekend  amount_per_login  duration_per_login  same_address_flag  \n",
      "count  78600.000000      78600.000000        78600.000000       78600.000000  \n",
      "mean       0.286667        192.920635           18.301119           0.001107  \n",
      "std        0.452207        192.685319            6.672045           0.033251  \n",
      "min        0.000000          0.001250            8.000000           0.000000  \n",
      "25%        0.000000         70.675853           13.500000           0.000000  \n",
      "50%        0.000000        122.335676           17.000000           0.000000  \n",
      "75%        1.000000        244.215919           21.333333           0.000000  \n",
      "max        1.000000       1557.150905           39.000000           1.000000  \n",
      "timestamp              object\n",
      "hour_of_day             int64\n",
      "sending_address        object\n",
      "receiving_address      object\n",
      "amount                float64\n",
      "transaction_type       object\n",
      "location_region        object\n",
      "ip_prefix             float64\n",
      "login_frequency         int64\n",
      "session_duration        int64\n",
      "purchase_pattern       object\n",
      "age_group              object\n",
      "risk_score            float64\n",
      "anomaly                object\n",
      "day_of_week             int64\n",
      "month                   int64\n",
      "fraud                    bool\n",
      "is_weekend              int64\n",
      "time_of_day            object\n",
      "amount_per_login      float64\n",
      "duration_per_login    float64\n",
      "same_address_flag       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.describe())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ecd02c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.location_region.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fe6aa1",
   "metadata": {},
   "source": [
    "## 3.5 Define Preprocessor and Pipeline <a id=\"preprocessor&pipeline\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf605d8",
   "metadata": {},
   "source": [
    "We will define the preprocessor and the pipeline before splitting the data. This ensures that the pipeline is ready to be applied immediately after the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b1b05da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns are numerical and which are categorical\n",
    "numerical_cols = ['amount', 'login_frequency', 'session_duration', 'amount_per_login', 'duration_per_login']\n",
    "categorical_cols = ['location_region', 'ip_prefix', 'purchase_pattern', 'age_group', 'day_of_week', 'month',\n",
    "                   'is_weekend', 'time_of_day', 'same_address_flag']\n",
    "\n",
    "# Create transformers for scaling and encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Incorporate the preprocessor and a classifier into a pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000, solver='sag', C=1.0))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8164d0c1",
   "metadata": {},
   "source": [
    "## 3.6 Train/Test Split <a id=\"train_test_split\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a281b6",
   "metadata": {},
   "source": [
    "We'll split our dataset into training and testing subsets, dropping unnecessary columns. This helps in evaluating the model on unseen data, providing a better indication of its performance in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f0978cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all previously engineered columns that obviously indicate fraud, plus additional unneeded fields\n",
    "X = df.drop(['anomaly', 'transaction_type', 'risk_score', 'fraud', \n",
    "             'timestamp', 'sending_address', 'receiving_address'], axis=1)  # Features\n",
    "y = df['fraud'] # Target variable\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8591a95",
   "metadata": {},
   "source": [
    "## 3.7 Apply Pipeline: Scaling, Encoding, and Model Training <a id=\"scaling&encoding\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f8ba245",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9166030534351145\n",
      "Testing Accuracy: 0.9204198473282442\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training dataset\n",
    "train_accuracy = pipeline.score(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing dataset\n",
    "test_accuracy = pipeline.score(X_test, y_test)\n",
    "\n",
    "# Output the results\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cee94b",
   "metadata": {},
   "source": [
    "We've successfully applied the pipeline to our training data, scaled our features, and encoded our categorical data. The numerical data is now standardized, with mean 0 and standard deviation 1 for each feature, and the categorical data is encoded --  both steps are critical for ML algorithms to perform optimally. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b90b1a",
   "metadata": {},
   "source": [
    "## 3.8 Model Evaluation <a id=\"modeleval\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ae542",
   "metadata": {},
   "source": [
    "This baseline logistic regression model predicts the most frequent class for all observations. For fraud detection, where the dataset is usually imbalanced and the majority of transactions are not fraudulent, this model would predict \"not fraud\" for all transactions.\n",
    "\n",
    "This is useful as a baseline because it sets a floor for model performance. Any sophisticated model should perform significantly better than this in terms of not just accuracy, but also other metrics like precision, recall, and the F1-score for the minority class (fraud).\n",
    "\n",
    "Starting with such a baseline provides a clear and simple comparison. When we later implement more complex models in the modeling stage like decision trees, ensemble methods, neural networks, etc., we can demonstrate their ability to outperform this simple baseline across relevant metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed2562d",
   "metadata": {},
   "source": [
    "We'll now detail the metrics used to evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b222674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9204198473282442\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "ROC AUC Score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuabe/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predicting the test set results\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)  \n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a01ec4",
   "metadata": {},
   "source": [
    "The warning message is fine and expected, since as mentioned the model is predicting only one class, resulting in precision, recall, and F1 scores of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b63fc3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       hour_of_day       amount location_region  ip_prefix  login_frequency  \\\n",
       " 31133           11   575.541393          Europe    172.160                7   \n",
       " 43844            1  1083.470998          Africa    192.000                7   \n",
       " 10032           14   571.455939   South America    172.000                1   \n",
       " 69576           11    46.931993          Europe    192.168                6   \n",
       " 13694            5   505.176300   South America    192.168                7   \n",
       " \n",
       "        session_duration purchase_pattern age_group  day_of_week  month  \\\n",
       " 31133                82       high_value   veteran            4     10   \n",
       " 43844               150       high_value   veteran            1      4   \n",
       " 10032                26           random       new            3      5   \n",
       " 69576               105       high_value   veteran            1      7   \n",
       " 13694               127       high_value   veteran            2      8   \n",
       " \n",
       "        is_weekend time_of_day  amount_per_login  duration_per_login  \\\n",
       " 31133           0     morning         82.220199           11.714286   \n",
       " 43844           0       night        154.781571           21.428571   \n",
       " 10032           0   afternoon        571.455939           26.000000   \n",
       " 69576           0     morning          7.821999           17.500000   \n",
       " 13694           0     morning         72.168043           18.142857   \n",
       " \n",
       "        same_address_flag  \n",
       " 31133                  0  \n",
       " 43844                  0  \n",
       " 10032                  0  \n",
       " 69576                  0  \n",
       " 13694                  0  ,\n",
       " 31133    False\n",
       " 43844    False\n",
       " 10032    False\n",
       " 69576    False\n",
       " 13694    False\n",
       " Name: fraud, dtype: bool)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(), y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e94ecf",
   "metadata": {},
   "source": [
    "## 3.9 Save Data <a id=\"savedata\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "874824d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62880, 48), (15720, 48))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recompile the transformed feature names directly from the transformers to ensure they are accurately captured\n",
    "cat_feature_names = pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out()\n",
    "all_feature_names = list(numerical_cols) + list(cat_feature_names)  # Combine numerical and categorical features\n",
    "\n",
    "# Apply the transformation to saved variables\n",
    "X_train_transformed_direct = pipeline.named_steps['preprocessor'].transform(X_train)\n",
    "X_test_transformed_direct = pipeline.named_steps['preprocessor'].transform(X_test)\n",
    "\n",
    "# Verify the actual shapes of the direct transformed outputs\n",
    "X_train_transformed_direct.shape, X_test_transformed_direct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0021d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sparse matrix to a dense format using the .toarray() method\n",
    "X_train_transformed_dense = X_train_transformed_direct.toarray()\n",
    "X_test_transformed_dense = X_test_transformed_direct.toarray()\n",
    "\n",
    "# Create DataFrames with the dense data\n",
    "X_train_transformed_df = pd.DataFrame(X_train_transformed_dense, columns=all_feature_names)\n",
    "X_test_transformed_df = pd.DataFrame(X_test_transformed_dense, columns=all_feature_names)\n",
    "\n",
    "# Save the features\n",
    "X_train_transformed_df.to_csv('/Users/joshuabe/Downloads/Capstone 3 - Metaverse Fraud Prediction/X_train.csv', index=False)\n",
    "X_test_transformed_df.to_csv('/Users/joshuabe/Downloads/Capstone 3 - Metaverse Fraud Prediction/X_test.csv', index=False)\n",
    "\n",
    "# Save the target variable data\n",
    "y_train.to_csv('/Users/joshuabe/Downloads/Capstone 3 - Metaverse Fraud Prediction/y_train.csv', index=False)\n",
    "y_test.to_csv('/Users/joshuabe/Downloads/Capstone 3 - Metaverse Fraud Prediction/y_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
